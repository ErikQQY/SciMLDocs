<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Uncertainty Quantified Deep Bayesian Model Discovery · Overview of Julia&#39;s SciML</title><meta name="title" content="Uncertainty Quantified Deep Bayesian Model Discovery · Overview of Julia&#39;s SciML"/><meta property="og:title" content="Uncertainty Quantified Deep Bayesian Model Discovery · Overview of Julia&#39;s SciML"/><meta property="twitter:title" content="Uncertainty Quantified Deep Bayesian Model Discovery · Overview of Julia&#39;s SciML"/><meta name="description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="og:description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="twitter:description" content="Documentation for Overview of Julia&#39;s SciML."/><meta property="og:url" content="https://docs.sciml.ai/stable/showcase/bayesian_neural_ode/"/><meta property="twitter:url" content="https://docs.sciml.ai/stable/showcase/bayesian_neural_ode/"/><link rel="canonical" href="https://docs.sciml.ai/stable/showcase/bayesian_neural_ode/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Overview of Julia&#39;s SciML logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Overview of Julia&#39;s SciML</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">SciML: Open Source Software for Scientific Machine Learning with Julia</a></li><li><span class="tocitem">Getting Started</span><ul><li><a class="tocitem" href="../../getting_started/getting_started/">Getting Started with Julia&#39;s SciML</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">New User Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../getting_started/installation/">Installing SciML Software</a></li><li><a class="tocitem" href="../../getting_started/first_simulation/">Build and run your first simulation with Julia&#39;s SciML</a></li><li><a class="tocitem" href="../../getting_started/first_optimization/">Solve your first optimization problem</a></li><li><a class="tocitem" href="../../getting_started/fit_simulation/">Fit a simulation to a dataset</a></li><li><a class="tocitem" href="../../getting_started/find_root/">Find the root of an equation (i.e. solve f(u)=0)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-2-3" type="checkbox"/><label class="tocitem" for="menuitem-2-3"><span class="docs-label">Comparison With Other Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../comparisons/python/">Getting Started with Julia&#39;s SciML for the Python User</a></li><li><a class="tocitem" href="../../comparisons/matlab/">Getting Started with  Julia&#39;s SciML for the MATLAB User</a></li><li><a class="tocitem" href="../../comparisons/r/">Getting Started with Julia&#39;s SciML for the R User</a></li><li><a class="tocitem" href="../../comparisons/cppfortran/">Getting Started with Julia&#39;s SciML for the C++/Fortran User</a></li></ul></li></ul></li><li><span class="tocitem">Showcase of Cool Examples</span><ul><li><a class="tocitem" href="../showcase/">The SciML Showcase</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox" checked/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Automated Model Discovery</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../missing_physics/">Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations</a></li><li class="is-active"><a class="tocitem" href>Uncertainty Quantified Deep Bayesian Model Discovery</a><ul class="internal"><li><a class="tocitem" href="#Step-1:-Import-Libraries"><span>Step 1: Import Libraries</span></a></li><li><a class="tocitem" href="#Setup:-Get-the-data-from-the-Spiral-ODE-example"><span>Setup: Get the data from the Spiral ODE example</span></a></li><li><a class="tocitem" href="#Step-2:-Define-the-Neural-ODE-architecture."><span>Step 2: Define the Neural ODE architecture.</span></a></li><li><a class="tocitem" href="#Step-3:-Define-the-loss-function-for-the-Neural-ODE."><span>Step 3: Define the loss function for the Neural ODE.</span></a></li><li><a class="tocitem" href="#Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above"><span>Step 4: Now we start integrating the Bayesian estimation workflow as prescribed by the AdvancedHMC interface with the NeuralODE defined above</span></a></li><li><a class="tocitem" href="#Step-5:-Plot-diagnostics"><span>Step 5: Plot diagnostics</span></a></li></ul></li><li><a class="tocitem" href="../blackhole/">Discovering the Relativistic Corrections to Binary Black Hole Dynamics</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-3" type="checkbox"/><label class="tocitem" for="menuitem-3-3"><span class="docs-label">Solving Difficult Equations Efficiently</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../brusselator/">Automated Efficient Solution of Nonlinear Partial Differential Equations</a></li><li><a class="tocitem" href="../pinngpu/">GPU-Accelerated Physics-Informed Neural Network (PINN) PDE Solvers</a></li><li><a class="tocitem" href="../massively_parallel_gpu/">Massively Data-Parallel ODE Solving on GPUs</a></li><li><a class="tocitem" href="../gpu_spde/">GPU-Accelerated Stochastic Partial Differential Equations</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3-4" type="checkbox"/><label class="tocitem" for="menuitem-3-4"><span class="docs-label">Useful Cool Wonky Things</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../ode_types/">Automatic Uncertainty Quantification, Arbitrary Precision, and Unit Checking in ODE Solutions using Julia&#39;s Type System</a></li><li><a class="tocitem" href="../symbolic_analysis/">Symbolic-Numeric Analysis of Parameter Identifiability and Model Stability</a></li><li><a class="tocitem" href="../optimization_under_uncertainty/">Optimization Under Uncertainty</a></li></ul></li></ul></li><li><span class="tocitem">What is SciML?</span><ul><li><a class="tocitem" href="../../overview/">Detailed Overview of the SciML Software Ecosystem</a></li><li><input class="collapse-toggle" id="menuitem-4-2" type="checkbox"/><label class="tocitem" for="menuitem-4-2"><span class="docs-label">Solvers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/equation_solvers/">Equation Solvers</a></li><li><a class="tocitem" href="../../highlevels/inverse_problems/">Parameter Estimation, Bayesian Analysis, and Inverse Problems</a></li><li><a class="tocitem" href="../../highlevels/partial_differential_equation_solvers/">Partial Differential Equations (PDE)</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-3" type="checkbox"/><label class="tocitem" for="menuitem-4-3"><span class="docs-label">Modeling Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/modeling_languages/">Modeling Languages</a></li><li><a class="tocitem" href="../../highlevels/model_libraries_and_importers/">Model Libraries and Importers</a></li><li><a class="tocitem" href="../../highlevels/symbolic_tools/">Symbolic Model Tooling and JuliaSymbolics</a></li><li><a class="tocitem" href="../../highlevels/array_libraries/">Modeling Array Libraries</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-4" type="checkbox"/><label class="tocitem" for="menuitem-4-4"><span class="docs-label">Simulation Analysis</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/parameter_analysis/">Parameter Analysis Utilities</a></li><li><a class="tocitem" href="../../highlevels/uncertainty_quantification/">Uncertainty Quantification</a></li><li><a class="tocitem" href="../../highlevels/plots_visualization/">SciML-Supported Plotting and Visualization Libraries</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-5" type="checkbox"/><label class="tocitem" for="menuitem-4-5"><span class="docs-label">Machine Learning</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/function_approximation/">Function Approximation</a></li><li><a class="tocitem" href="../../highlevels/implicit_layers/">Implicit Layer Deep Learning</a></li><li><a class="tocitem" href="../../highlevels/symbolic_learning/">Symbolic Learning and Artificial Intelligence</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-6" type="checkbox"/><label class="tocitem" for="menuitem-4-6"><span class="docs-label">Developer Tools</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/numerical_utilities/">SciML Numerical Utility Libraries</a></li><li><a class="tocitem" href="../../highlevels/interfaces/">The SciML Interface Libraries</a></li><li><a class="tocitem" href="../../highlevels/developer_documentation/">Developer Documentation</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4-7" type="checkbox"/><label class="tocitem" for="menuitem-4-7"><span class="docs-label">Extra Learning Resources</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../highlevels/learning_resources/">Curated Learning, Teaching, and Training Resources</a></li></ul></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Showcase of Cool Examples</a></li><li><a class="is-disabled">Automated Model Discovery</a></li><li class="is-active"><a href>Uncertainty Quantified Deep Bayesian Model Discovery</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Uncertainty Quantified Deep Bayesian Model Discovery</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/SciMLDocs" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/SciMLDocs/blob/main/docs/src/showcase/bayesian_neural_ode.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="bnode"><a class="docs-heading-anchor" href="#bnode">Uncertainty Quantified Deep Bayesian Model Discovery</a><a id="bnode-1"></a><a class="docs-heading-anchor-permalink" href="#bnode" title="Permalink"></a></h1><p>In this tutorial, we show how SciML can combine the differential equation solvers seamlessly with Bayesian estimation libraries like AdvancedHMC.jl and Turing.jl. This enables converting Neural ODEs to Bayesian Neural ODEs, which enables us to estimate the error in the Neural ODE estimation and forecasting. In this tutorial, a working example of the Bayesian Neural ODE: NUTS sampler is shown.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>For more details, have a look at this paper: https://arxiv.org/abs/2012.07244</p></div></div><h2 id="Step-1:-Import-Libraries"><a class="docs-heading-anchor" href="#Step-1:-Import-Libraries">Step 1: Import Libraries</a><a id="Step-1:-Import-Libraries-1"></a><a class="docs-heading-anchor-permalink" href="#Step-1:-Import-Libraries" title="Permalink"></a></h2><p>For this example, we will need the following libraries:</p><pre><code class="language-julia hljs"># SciML Libraries
using SciMLSensitivity, DifferentialEquations

# ML Tools
using Lux, Zygote

# External Tools
using Random, Plots, AdvancedHMC, MCMCChains, StatsPlots, ComponentArrays</code></pre><h2 id="Setup:-Get-the-data-from-the-Spiral-ODE-example"><a class="docs-heading-anchor" href="#Setup:-Get-the-data-from-the-Spiral-ODE-example">Setup: Get the data from the Spiral ODE example</a><a id="Setup:-Get-the-data-from-the-Spiral-ODE-example-1"></a><a class="docs-heading-anchor-permalink" href="#Setup:-Get-the-data-from-the-Spiral-ODE-example" title="Permalink"></a></h2><p>We will also need data to fit against. As a demonstration, we will generate our data using a simple cubic ODE <code>u&#39; = A*u^3</code> as follows:</p><pre><code class="language-julia hljs">u0 = [2.0; 0.0]
datasize = 40
tspan = (0.0, 1)
tsteps = range(tspan[1], tspan[2], length = datasize)
function trueODEfunc(du, u, p, t)
    true_A = [-0.1 2.0; -2.0 -0.1]
    du .= ((u .^ 3)&#39;true_A)&#39;
end
prob_trueode = ODEProblem(trueODEfunc, u0, tspan)
ode_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×40 Matrix{Float64}:
 2.0  1.97895   1.94728  1.87998  1.74775  …   0.353996   0.53937   0.718119
 0.0  0.403905  0.79233  1.15176  1.45561     -1.54217   -1.52816  -1.50614</code></pre><p>We will want to train a neural network to capture the dynamics that fit <code>ode_data</code>.</p><h2 id="Step-2:-Define-the-Neural-ODE-architecture."><a class="docs-heading-anchor" href="#Step-2:-Define-the-Neural-ODE-architecture.">Step 2: Define the Neural ODE architecture.</a><a id="Step-2:-Define-the-Neural-ODE-architecture.-1"></a><a class="docs-heading-anchor-permalink" href="#Step-2:-Define-the-Neural-ODE-architecture." title="Permalink"></a></h2><p>Note that this step potentially offers a lot of flexibility in the number of layers/ number of units in each layer. It may not necessarily be true that a 100 units architecture is better at prediction/forecasting than a 50 unit architecture. On the other hand, a complicated architecture can take a huge computational time without increasing performance.</p><pre><code class="language-julia hljs">dudt2 = Lux.Chain(x -&gt; x .^ 3,
                   Lux.Dense(2, 50, tanh),
                   Lux.Dense(50, 2))

rng = Random.default_rng()
p, st = Lux.setup(rng, dudt2)
const _st = st
function neuralodefunc(u, p, t)
    dudt2(u, p, _st)[1]
end
function prob_neuralode(u0, p)
    prob = ODEProblem(neuralodefunc, u0, tspan, p)
    sol = solve(prob, Tsit5(), saveat = tsteps)
end
p = ComponentArray{Float64}(p)
const _p = p</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ComponentVector{Float64}(layer_1 = Float64[], layer_2 = (weight = [-0.10688556730747223 -0.09835749864578247; 0.071578249335289 -0.13026778399944305; … ; -0.013310215435922146 0.3381478786468506; 0.20282208919525146 -0.028967102989554405], bias = [0.0; 0.0; … ; 0.0; 0.0;;]), layer_3 = (weight = [0.1465582251548767 -0.2888965308666229 … -0.17990939319133759 0.3097148537635803; -0.17788447439670563 0.027322828769683838 … 0.014888404868543148 -0.04003366082906723], bias = [0.0; 0.0;;]))</code></pre><p>Note that the <code>f64</code> is required to put the Lux neural network into Float64 precision.</p><h2 id="Step-3:-Define-the-loss-function-for-the-Neural-ODE."><a class="docs-heading-anchor" href="#Step-3:-Define-the-loss-function-for-the-Neural-ODE.">Step 3: Define the loss function for the Neural ODE.</a><a id="Step-3:-Define-the-loss-function-for-the-Neural-ODE.-1"></a><a class="docs-heading-anchor-permalink" href="#Step-3:-Define-the-loss-function-for-the-Neural-ODE." title="Permalink"></a></h2><pre><code class="language-julia hljs">function predict_neuralode(p)
    p = p isa ComponentArray ? p : convert(typeof(_p),p)
    Array(prob_neuralode(u0, p))
end
function loss_neuralode(p)
    pred = predict_neuralode(p)
    loss = sum(abs2, ode_data .- pred)
    return loss, pred
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">loss_neuralode (generic function with 1 method)</code></pre><h2 id="Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above"><a class="docs-heading-anchor" href="#Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above">Step 4: Now we start integrating the Bayesian estimation workflow as prescribed by the AdvancedHMC interface with the NeuralODE defined above</a><a id="Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above-1"></a><a class="docs-heading-anchor-permalink" href="#Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above" title="Permalink"></a></h2><p>The AdvancedHMC interface requires us to specify: (a) the Hamiltonian log density and its gradient , (b) the sampler and (c) the step size adaptor function.</p><p>For the Hamiltonian log density, we use the loss function. The θ*θ term denotes the use of Gaussian priors.</p><p>The user can make several modifications to Step 4. The user can try different acceptance ratios, warmup samples and posterior samples. One can also use the Variational Inference (ADVI) framework, which doesn&#39;t work quite as well as NUTS. The SGLD (Stochastic Gradient Langevin Descent) sampler is seen to have a better performance than NUTS. Have a look at https://sebastiancallh.github.io/post/langevin/ for a brief introduction to SGLD.</p><pre><code class="language-julia hljs">l(θ) = -sum(abs2, ode_data .- predict_neuralode(θ)) - sum(θ .* θ)
function dldθ(θ)
    x, lambda = Zygote.pullback(l, θ)
    grad = first(lambda(1))
    return x, grad
end

metric = DiagEuclideanMetric(length(p))
h = Hamiltonian(metric, l, dldθ)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Hamiltonian(metric=DiagEuclideanMetric([1.0, 1.0, 1.0, 1.0, 1.0, 1 ...]), kinetic=AdvancedHMC.GaussianKinetic())</code></pre><p>We use the NUTS sampler with an acceptance ratio of δ= 0.45 in this example. In addition, we use Nesterov Dual Averaging for the Step Size adaptation.</p><p>We sample using 500 warmup samples and 500 posterior samples.</p><pre><code class="language-julia hljs">integrator = Leapfrog(find_good_stepsize(h, p))
kernel = HMCKernel(Trajectory{MultinomialTS}(integrator, GeneralisedNoUTurn()))
adaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.45, integrator))
samples, stats = sample(h, kernel, p, 500, adaptor, 500; progress = true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(ComponentArrays.ComponentVector{Float64, Vector{Float64}, Tuple{ComponentArrays.Axis{(layer_1 = 1:0, layer_2 = ViewAxis(1:150, Axis(weight = ViewAxis(1:100, ShapedAxis((50, 2))), bias = ViewAxis(101:150, ShapedAxis((50, 1))))), layer_3 = ViewAxis(151:252, Axis(weight = ViewAxis(1:100, ShapedAxis((2, 50))), bias = ViewAxis(101:102, ShapedAxis((2, 1))))))}}}[(layer_1 = Float64[], layer_2 = (weight = [-0.11933045750868868 -0.11530420766758298; 0.09820652078419777 -0.13786186702359127; … ; 0.16402872261100263 0.34075378113704347; 0.18373119868176915 -0.04240867636847502], bias = [-0.01590555030106112; 0.012104793961625122; … ; 0.013745929462231533; -0.042965331750167784;;]), layer_3 = (weight = [0.21503242357144553 -0.32056369998139805 … -0.1665410390828656 0.28649582847273614; -0.1553650398724045 0.05284758171943835 … 0.039233942029407665 -0.034863251773797704], bias = [-0.03941074771470541; -0.06765292036664732;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.11933045750868868 -0.11530420766758298; 0.09820652078419777 -0.13786186702359127; … ; 0.16402872261100263 0.34075378113704347; 0.18373119868176915 -0.04240867636847502], bias = [-0.01590555030106112; 0.012104793961625122; … ; 0.013745929462231533; -0.042965331750167784;;]), layer_3 = (weight = [0.21503242357144553 -0.32056369998139805 … -0.1665410390828656 0.28649582847273614; -0.1553650398724045 0.05284758171943835 … 0.039233942029407665 -0.034863251773797704], bias = [-0.03941074771470541; -0.06765292036664732;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.11933045750868868 -0.11530420766758298; 0.09820652078419777 -0.13786186702359127; … ; 0.16402872261100263 0.34075378113704347; 0.18373119868176915 -0.04240867636847502], bias = [-0.01590555030106112; 0.012104793961625122; … ; 0.013745929462231533; -0.042965331750167784;;]), layer_3 = (weight = [0.21503242357144553 -0.32056369998139805 … -0.1665410390828656 0.28649582847273614; -0.1553650398724045 0.05284758171943835 … 0.039233942029407665 -0.034863251773797704], bias = [-0.03941074771470541; -0.06765292036664732;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.11933045750868868 -0.11530420766758298; 0.09820652078419777 -0.13786186702359127; … ; 0.16402872261100263 0.34075378113704347; 0.18373119868176915 -0.04240867636847502], bias = [-0.01590555030106112; 0.012104793961625122; … ; 0.013745929462231533; -0.042965331750167784;;]), layer_3 = (weight = [0.21503242357144553 -0.32056369998139805 … -0.1665410390828656 0.28649582847273614; -0.1553650398724045 0.05284758171943835 … 0.039233942029407665 -0.034863251773797704], bias = [-0.03941074771470541; -0.06765292036664732;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.07943848271476601 -0.1263800566977668; 0.11094764483456963 -0.15549287326035316; … ; 0.19155878064893808 0.3594191970858737; 0.18130625793481703 -0.05748562951229358], bias = [-0.015552974535599548; 0.0167458048507291; … ; 0.017531534137763538; -0.04737205212931464;;]), layer_3 = (weight = [0.20243006315668713 -0.3401612880871289 … -0.19241657140329127 0.27784706370278217; -0.11834446278381205 0.07602683644058128 … 0.027987618604796323 -0.011551490525512322], bias = [-0.09908785532119824; -0.055267280450075076;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.20655565376819063 -0.15668127051782357; 0.19155533225371102 -0.10925230612608333; … ; 0.04779415721438127 0.38915431130484385; 0.0736936881114778 -0.03476023008831609], bias = [0.08762388358153252; 0.02825380640491415; … ; 0.03154533809363357; -0.09016821632258828;;]), layer_3 = (weight = [0.37217159124746585 -0.47465062554993087 … -0.26240497290556686 0.252354676096435; -0.22980463639213283 0.0716119240835858 … 0.07363007013224471 0.03386913791391694], bias = [-0.31644161011163807; 0.015050817407080646;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.1956413147315072 -0.3045311417456575; 0.11810666217103631 -0.053376447281575146; … ; 0.12148357970404003 0.4805227627154557; -0.018102476406554487 -0.11418453290906318], bias = [-0.5999149060475413; 0.07663383667281481; … ; 0.4103066864551542; -0.09746815691020035;;]), layer_3 = (weight = [0.7984222484681346 -0.43109860365053854 … -0.447798017188425 -0.1756491844963622; -0.2639960854519765 0.49900288440777774 … 0.2627495623039184 -0.12192842669203727], bias = [-1.1062318476926127; -0.4836449579978507;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.1956413147315072 -0.3045311417456575; 0.11810666217103631 -0.053376447281575146; … ; 0.12148357970404003 0.4805227627154557; -0.018102476406554487 -0.11418453290906318], bias = [-0.5999149060475413; 0.07663383667281481; … ; 0.4103066864551542; -0.09746815691020035;;]), layer_3 = (weight = [0.7984222484681346 -0.43109860365053854 … -0.447798017188425 -0.1756491844963622; -0.2639960854519765 0.49900288440777774 … 0.2627495623039184 -0.12192842669203727], bias = [-1.1062318476926127; -0.4836449579978507;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.202004860588589 -0.46198046900026696; 0.4469013266316403 0.10168563121475266; … ; 0.06122600775080886 0.7978628618718192; -0.6349633170329909 -0.5326094477176719], bias = [-0.5344011289616959; 0.4174824950549737; … ; 0.5164401153038671; -0.07902778409541641;;]), layer_3 = (weight = [1.1583229651992322 -0.7345216384799244 … -0.7504361054207055 -0.24694723054956408; -0.5451775563993052 0.18724967556241742 … 0.6700236081526381 -0.4042692500269774], bias = [-1.0772355932325604; -0.7658201962626201;;])), (layer_1 = Float64[], layer_2 = (weight = [-0.6053158174363976 -0.2020773227409462; 0.302479514784827 0.5966639365936743; … ; -0.020617522906570426 0.6338583212218261; -0.49566982998998266 -0.42696956319346147], bias = [0.0971416259679333; 0.40728471178117787; … ; 0.03550093464826552; -0.08355018691264607;;]), layer_3 = (weight = [1.8305466465076137 -1.0524935768973955 … -1.754881732600057 0.06825266569025933; -0.24524859925957154 -0.4087092461098186 … 0.09284338518567462 -0.8400314236037495], bias = [-0.5735876325798388; -0.3691392147556117;;]))  …  (layer_1 = Float64[], layer_2 = (weight = [1.3212047544989873 0.021902206531131008; 0.38766966068581765 0.18152543792890258; … ; 0.6016542244783621 1.1046140481758362; 0.17551640813437108 0.25120541139318175], bias = [0.09933346313311724; 0.5043648450984115; … ; -0.06468689418767394; 0.23625351082769325;;]), layer_3 = (weight = [0.7229719220503537 0.03135653719011436 … -0.9811741541471157 -0.6664780816880463; 1.3777605887363336 -0.1155741387970713 … 1.1153196587796608 0.0692456335149397], bias = [-0.5231008356145641; 0.36398092558345746;;])), (layer_1 = Float64[], layer_2 = (weight = [1.066962538457715 -0.28008435319891434; -1.2963675192263606 0.21911481697135432; … ; 0.219870149830888 0.6072916697823915; -0.9565899989518635 -0.7543125861119697], bias = [1.7374002754215245; -0.32344889306889313; … ; -0.507530694751744; -0.2784029803852039;;]), layer_3 = (weight = [-1.5508503803162172 -0.6244727720673103 … 1.0728708389451473 -0.4938018291769046; 0.27550416470178013 -1.6311090319185397 … 0.3454074423667774 -1.032490852803708], bias = [-0.267853288818015; -0.5524812216905755;;])), (layer_1 = Float64[], layer_2 = (weight = [0.6542207705422691 0.3816406046637623; -0.7225964593732074 -0.27105345865683095; … ; 0.1313393253728977 0.2065687582017603; -1.2884563532676996 -1.4143406554567899], bias = [0.7275830325871371; -0.10400382032332574; … ; -0.6831497294742521; -0.19350178290538958;;]), layer_3 = (weight = [-0.6367221481012573 -0.24075210106945313 … 0.1535443784807445 0.1782693268792906; 0.02796606148551154 0.09998424388241078 … 0.276184579084455 -0.8218665428577036], bias = [-0.07615412434329114; -0.7139392532352937;;])), (layer_1 = Float64[], layer_2 = (weight = [0.2007273094633678 -0.27030164775332527; -0.046358085000581015 1.165161186504504; … ; 0.5332440659068153 -0.20249034428616028; 0.29979206475433695 0.27600172310707005], bias = [-1.2490133505059857; 0.32508177307556124; … ; 0.11583187112189726; -0.24015048722516502;;]), layer_3 = (weight = [-0.4558713170674912 0.549245279833916 … 0.30080906721115 0.11881352307675311; -1.0798474322936906 -1.118389283219529 … -0.8912163014907181 -0.09384951570896226], bias = [-0.9957905590828439; 0.5481717779352104;;])), (layer_1 = Float64[], layer_2 = (weight = [0.2007273094633678 -0.27030164775332527; -0.046358085000581015 1.165161186504504; … ; 0.5332440659068153 -0.20249034428616028; 0.29979206475433695 0.27600172310707005], bias = [-1.2490133505059857; 0.32508177307556124; … ; 0.11583187112189726; -0.24015048722516502;;]), layer_3 = (weight = [-0.4558713170674912 0.549245279833916 … 0.30080906721115 0.11881352307675311; -1.0798474322936906 -1.118389283219529 … -0.8912163014907181 -0.09384951570896226], bias = [-0.9957905590828439; 0.5481717779352104;;])), (layer_1 = Float64[], layer_2 = (weight = [0.05730183889375972 -0.12104056030416764; -0.2593910144063701 1.0618199090298934; … ; 0.20049259637234498 -0.2146739532244878; 0.10002191917579642 0.30711735968540205], bias = [-1.1159268342057298; 0.4752886658786863; … ; 0.0934986381899393; 0.16675108239712097;;]), layer_3 = (weight = [-0.21101491151392532 0.5539158341979965 … 0.5172796780480086 -0.21105461948226353; -1.2280941601246476 -1.215335442374201 … -0.6510932476419733 -0.1041899645066176], bias = [-0.687477015715061; 0.5352088509714718;;])), (layer_1 = Float64[], layer_2 = (weight = [0.5869180677576449 0.5558807495551739; -0.18610842953476223 -0.8207070632373827; … ; -0.9494701887281125 -0.041124978887001874; -0.30311898286060757 0.03830058875265826], bias = [1.2169073066888638; -0.30617508159724743; … ; 0.044676875136771606; -0.09652609296931525;;]), layer_3 = (weight = [-0.24512183440434057 -0.21761159021788545 … -0.16063249851218264 0.06782369301306458; 1.9351121741349828 0.6724515086542374 … -0.0019805781439137457 -0.3217989978479287], bias = [-0.7294808934942851; 0.11852029238498461;;])), (layer_1 = Float64[], layer_2 = (weight = [0.6522602374660322 1.199294769442404; 0.022389368820179372 -0.8240275251580081; … ; -1.0366654759594538 -0.04923296833184156; -0.3232792621813341 0.716807444552157], bias = [1.492555167263947; -0.5692297583640742; … ; -0.024179748982015276; 0.6312159852492809;;]), layer_3 = (weight = [-0.6789413552482082 -0.8528975355516999 … -0.17588047117592828 -0.5313896189321439; 1.7891489346234408 0.5548817549284343 … 0.3962645218750518 -0.18115594120394618], bias = [-0.8630856154732882; 0.24902981593199355;;])), (layer_1 = Float64[], layer_2 = (weight = [0.64764024991533 1.092314649303496; -0.19200217017691112 -0.649099071879741; … ; -0.8310056322016377 -0.08159881625918651; -0.6636835260574501 0.6134635406916742], bias = [1.433615821108322; -0.5002220508730961; … ; 0.40781298821487655; 0.4825001606870579;;]), layer_3 = (weight = [-0.368232188326592 -0.9489563073318373 … -0.31145550608805894 -0.20528026808229521; 1.8830663193765322 0.25449909075671845 … 0.45811232138446434 -0.33459670848780776], bias = [-0.9242199510113185; 0.10740760148362541;;])), (layer_1 = Float64[], layer_2 = (weight = [0.6574160129531094 1.0568924350911735; -0.24605816505465794 -0.6819651868629699; … ; -0.8502985481112973 -0.10116814402810195; -0.6069088794126319 0.5888640690083794], bias = [1.4564739884439857; -0.4495772884187767; … ; 0.4126090295617445; 0.5210571622641741;;]), layer_3 = (weight = [-0.3603993451069857 -0.9481984417182895 … -0.30318992633323 -0.23772757799518843; 1.8924858739855956 0.2690172550872252 … 0.4086850023222427 -0.3310471032132094], bias = [-0.8971237768129612; 0.07018005419955742;;]))], NamedTuple[(n_steps = 15, is_accept = true, acceptance_rate = 0.9361248999680097, log_density = -339.7234923127616, hamiltonian_energy = 756.2235633278124, hamiltonian_energy_error = -80.47180319430868, max_hamiltonian_energy_error = -80.47180319430868, tree_depth = 4, numerical_error = false, step_size = 0.025, nom_step_size = 0.025, is_adapt = true), (n_steps = 1, is_accept = true, acceptance_rate = 0.0, log_density = -339.7234923127616, hamiltonian_energy = 466.87078822434137, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 92969.62386692638, tree_depth = 0, numerical_error = true, step_size = 0.6050580309457656, nom_step_size = 0.6050580309457656, is_adapt = true), (n_steps = 1, is_accept = true, acceptance_rate = 0.0, log_density = -339.7234923127616, hamiltonian_energy = 461.388242785199, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 3071.4850014947465, tree_depth = 0, numerical_error = true, step_size = 0.2722193359877766, nom_step_size = 0.2722193359877766, is_adapt = true), (n_steps = 12, is_accept = true, acceptance_rate = 1.7231299900442488e-38, log_density = -339.7234923127616, hamiltonian_energy = 469.6516925281014, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 2154.48560052212, tree_depth = 3, numerical_error = true, step_size = 0.08298091223343115, nom_step_size = 0.08298091223343115, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.5590551181102362, log_density = -275.25942928183605, hamiltonian_energy = 440.5199616125892, hamiltonian_energy_error = -10.912752193526217, max_hamiltonian_energy_error = 609.4254287452376, tree_depth = 6, numerical_error = false, step_size = 0.021184003528993644, nom_step_size = 0.021184003528993644, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.5368232055849738, log_density = -172.69901496046833, hamiltonian_energy = 405.3917319283444, hamiltonian_energy_error = -4.975338015393902, max_hamiltonian_energy_error = 7.462408274069617, tree_depth = 6, numerical_error = false, step_size = 0.026338257256036973, nom_step_size = 0.026338257256036973, is_adapt = true), (n_steps = 18, is_accept = true, acceptance_rate = 0.9322365706485408, log_density = -109.50213682383978, hamiltonian_energy = 296.6012711178315, hamiltonian_energy_error = -0.7244117225807827, max_hamiltonian_energy_error = 5776.832462790286, tree_depth = 4, numerical_error = true, step_size = 0.03233489064813714, nom_step_size = 0.03233489064813714, is_adapt = true), (n_steps = 5, is_accept = true, acceptance_rate = 9.68020929592214e-7, log_density = -109.50213682383978, hamiltonian_energy = 222.80032336819585, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 1887.3186044852666, tree_depth = 2, numerical_error = true, step_size = 0.1402258971713914, nom_step_size = 0.1402258971713914, is_adapt = true), (n_steps = 109, is_accept = true, acceptance_rate = 0.17322575617375266, log_density = -81.22456052529733, hamiltonian_energy = 243.55016874011238, hamiltonian_energy_error = -4.523973592837137, max_hamiltonian_energy_error = 1008.4792793454649, tree_depth = 6, numerical_error = true, step_size = 0.033901606163626676, nom_step_size = 0.033901606163626676, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.9517052105546253, log_density = -107.89371322403069, hamiltonian_energy = 218.1753346784497, hamiltonian_energy_error = -0.21402284779097158, max_hamiltonian_energy_error = 0.4889723778235293, tree_depth = 7, numerical_error = false, step_size = 0.014010068356534627, nom_step_size = 0.014010068356534627, is_adapt = true)  …  (n_steps = 34, is_accept = true, acceptance_rate = 0.0035879480251546384, log_density = -134.84652651726256, hamiltonian_energy = 277.9451688027475, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 2795.825430758794, tree_depth = 5, numerical_error = true, step_size = 0.07948051403031793, nom_step_size = 0.07948051403031793, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.6440453373417062, log_density = -146.32257731522412, hamiltonian_energy = 280.9084362756596, hamiltonian_energy_error = 0.08018847233415727, max_hamiltonian_energy_error = 1.7439078940257104, tree_depth = 7, numerical_error = false, step_size = 0.026338975719343606, nom_step_size = 0.026338975719343606, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.38791941492327353, log_density = -130.58622133775776, hamiltonian_energy = 280.4396912109112, hamiltonian_energy_error = 1.4588312786754614, max_hamiltonian_energy_error = 215.90599711969787, tree_depth = 7, numerical_error = false, step_size = 0.043778149655295966, nom_step_size = 0.043778149655295966, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.9119816738919713, log_density = -144.94586892361798, hamiltonian_energy = 265.34111468312443, hamiltonian_energy_error = -0.5206356384266542, max_hamiltonian_energy_error = 0.9469422931906593, tree_depth = 7, numerical_error = false, step_size = 0.038319282157752946, nom_step_size = 0.038319282157752946, is_adapt = true), (n_steps = 2, is_accept = true, acceptance_rate = 5.792578624093757e-308, log_density = -144.94586892361798, hamiltonian_energy = 271.2627009461049, hamiltonian_energy_error = 0.0, max_hamiltonian_energy_error = 2857.3215711240723, tree_depth = 1, numerical_error = true, step_size = 0.12176389359685294, nom_step_size = 0.12176389359685294, is_adapt = true), (n_steps = 127, is_accept = true, acceptance_rate = 0.060599240962078256, log_density = -148.23547131753588, hamiltonian_energy = 271.37864524254167, hamiltonian_energy_error = 0.639019677766214, max_hamiltonian_energy_error = 115.46785434977062, tree_depth = 7, numerical_error = false, step_size = 0.04114443799837268, nom_step_size = 0.04114443799837268, is_adapt = true), (n_steps = 255, is_accept = true, acceptance_rate = 0.9586188044712052, log_density = -137.5831507706523, hamiltonian_energy = 278.45290427098706, hamiltonian_energy_error = -0.34620208562677135, max_hamiltonian_energy_error = 1.2899583493352793, tree_depth = 8, numerical_error = false, step_size = 0.01634660683795468, nom_step_size = 0.01634660683795468, is_adapt = true), (n_steps = 54, is_accept = true, acceptance_rate = 0.6330519085602696, log_density = -135.86827553736117, hamiltonian_energy = 268.6245748348895, hamiltonian_energy_error = -0.6194841400472342, max_hamiltonian_energy_error = 1367.204766611211, tree_depth = 5, numerical_error = true, step_size = 0.057043537752852994, nom_step_size = 0.057043537752852994, is_adapt = true), (n_steps = 19, is_accept = true, acceptance_rate = 0.14585039113924148, log_density = -136.96178231658064, hamiltonian_energy = 263.7684264168776, hamiltonian_energy_error = -0.32484283010904846, max_hamiltonian_energy_error = 1113.8296370421026, tree_depth = 4, numerical_error = true, step_size = 0.08989029015409938, nom_step_size = 0.08989029015409938, is_adapt = true), (n_steps = 68, is_accept = true, acceptance_rate = 0.285672881328168, log_density = -136.31570172848433, hamiltonian_energy = 275.1627450103142, hamiltonian_energy_error = -0.01499464689720753, max_hamiltonian_energy_error = 1669.6124225688359, tree_depth = 6, numerical_error = true, step_size = 0.044303253234331465, nom_step_size = 0.044303253234331465, is_adapt = true)])</code></pre><h2 id="Step-5:-Plot-diagnostics"><a class="docs-heading-anchor" href="#Step-5:-Plot-diagnostics">Step 5: Plot diagnostics</a><a id="Step-5:-Plot-diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Step-5:-Plot-diagnostics" title="Permalink"></a></h2><p>Now let&#39;s make sure the fit is good. This can be done by looking at the chain mixing plot and the autocorrelation plot. First, let&#39;s create the chain mixing plot using the plot recipes from ????</p><pre><code class="language-julia hljs">samples = hcat(samples...)
samples_reduced = samples[1:5, :]
samples_reshape = reshape(samples_reduced, (500, 5, 1))
Chain_Spiral = Chains(samples_reshape)
plot(Chain_Spiral)</code></pre><img src="312dfeb8.svg" alt="Example block output"/><p>Now we check the autocorrelation plot:</p><pre><code class="language-julia hljs">autocorplot(Chain_Spiral)</code></pre><img src="585e3afe.svg" alt="Example block output"/><p>As another diagnostic, let&#39;s check the result on retrodicted data. To do this, we generate solutions of the Neural ODE on samples of the neural network parameters, and check the results of the predictions against the data. Let&#39;s start by looking at the time series:</p><pre><code class="language-julia hljs">pl = scatter(tsteps, ode_data[1, :], color = :red, label = &quot;Data: Var1&quot;, xlabel = &quot;t&quot;,
             title = &quot;Spiral Neural ODE&quot;)
scatter!(tsteps, ode_data[2, :], color = :blue, label = &quot;Data: Var2&quot;)
for k in 1:300
    resol = predict_neuralode(samples[:, 100:end][:, rand(1:400)])
    plot!(tsteps, resol[1, :], alpha = 0.04, color = :red, label = &quot;&quot;)
    plot!(tsteps, resol[2, :], alpha = 0.04, color = :blue, label = &quot;&quot;)
end

losses = map(x -&gt; loss_neuralode(x)[1], eachcol(samples))
idx = findmin(losses)[2]
prediction = predict_neuralode(samples[:, idx])
plot!(tsteps, prediction[1, :], color = :black, w = 2, label = &quot;&quot;)
plot!(tsteps, prediction[2, :], color = :black, w = 2, label = &quot;Best fit prediction&quot;,
      ylims = (-2.5, 3.5))</code></pre><img src="9857e875.svg" alt="Example block output"/><p>That showed the time series form. We can similarly do a phase-space plot:</p><pre><code class="language-julia hljs">pl = scatter(ode_data[1, :], ode_data[2, :], color = :red, label = &quot;Data&quot;, xlabel = &quot;Var1&quot;,
             ylabel = &quot;Var2&quot;, title = &quot;Spiral Neural ODE&quot;)
for k in 1:300
    resol = predict_neuralode(samples[:, 100:end][:, rand(1:400)])
    plot!(resol[1, :], resol[2, :], alpha = 0.04, color = :red, label = &quot;&quot;)
end
plot!(prediction[1, :], prediction[2, :], color = :black, w = 2,
      label = &quot;Best fit prediction&quot;, ylims = (-2.5, 3))</code></pre><img src="3eb7f695.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../missing_physics/">« Automatically Discover Missing Physics by Embedding Machine Learning into Differential Equations</a><a class="docs-footer-nextpage" href="../blackhole/">Discovering the Relativistic Corrections to Binary Black Hole Dynamics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 27 May 2024 01:55">Monday 27 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
